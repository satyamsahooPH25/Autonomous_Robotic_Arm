# -*- coding: utf-8 -*-
"""Untitled0.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1nW92Wv7CO37Jbt3kTqY4g2yQ7e9ASSX3
"""

from google.colab import drive
drive.mount('/content/drive')

import cv2 as cv
from PIL import Image,ImageFilter
import tensorflow as tf
import numpy as np
import os
import zipfile
import json
def empty(a):
    pass
'''cv.namedWindow("Parameters")
cv.resizeWindow("Parameters",640,240)
cv.createTrackbar("Threshhold1","Parameters",150,255,empty)
cv.createTrackbar("Threshhold2","Parameters",255,255,empty)'''
def getContour(img,imgContour):
    contours,hierarchy=cv.findContours(img,cv.RETR_EXTERNAL,cv.CHAIN_APPROX_SIMPLE)
    contours=list(contours)
    c=0
    d=0
    new=[]
    #print(len(contours))
    for cnt in contours:
        #if cv.contourArea(cnt,True)>10:
            peri=cv.arcLength(cnt,True)
            if peri>100:
                approx=cv.approxPolyDP(cnt,0.02*peri,True)
                if len(approx)>=0:
                    cv.drawContours(imgContour,contours,-1,(255,0,255),0)
                    new.append(cnt)
                    d=d+1
                #cv.imshow(';;',imgContour)
    #print(d)
    return(imgContour,new)

def getx(img):
    img= cv.resize(img,(256,256), interpolation= cv.INTER_LINEAR)
    imgcontour=img.copy()
    imgcontour2=img.copy()
    imgcontour3=img.copy()
    imgcontour4=img.copy()
    img=cv.cvtColor(img,cv.COLOR_BGR2GRAY)
    #img=cv.GaussianBlur(img,(7,7),2)
    '''threshhold1=cv.getTrackbarPos("Threshhold1","Parameters")
    threshhold2=cv.getTrackbarPos("Threshhold2","Parameters")'''
    img=cv.Canny(img,42,102)
    #cv.imshow("canny",img)
    final,new=getContour(img,imgcontour)
    dark=np.zeros((256,256),dtype=np.float32)
    dark2=dark.copy()
    dark3=dark.copy()
    det=np.zeros((256,256),dtype=np.float32)
    setf=[]
    for i in range(0,len(new)):
        cv.drawContours(dark,new,i,(255,0,255))
        cv.drawContours(det,new,i,(255,0,255),3)
        c=dark.copy()
        setf.append(dark)
        #cv.imshow(str(i),dark)
        dark=dark2.copy()
        dark3=dark2.copy()
    #cv.imshow('contour',det)
    kernel=np.ones((2,2))
    pet=np.zeros((256,256),dtype=np.float32)
    src=np.copy(det)
    slice1Copy = (src).astype(np.uint8)
    linesP = cv.HoughLinesP(slice1Copy, 1, np.pi / 180, 50, None, 50, 10)
    if linesP is not None:
            for i in range(0, len(linesP)):
              l = linesP[i][0]
              net=np.zeros((256,256),dtype=np.float32)
              final=cv.line(pet, (l[0], l[1]), (l[2], l[3]), (255,0,0), 2, cv.LINE_AA)
              net=cv.line(pet, (l[0], l[1]), (l[2], l[3]), (255,0,0), 2, cv.LINE_AA)
              #cv.imshow(str(i),net)
    #print(linesP)
    #cv.imshow('houghline',final)
    return final

zip_ref=zipfile.ZipFile('/content/drive/MyDrive/square.zip','r')
zip_ref.extractall('/temp')
zip_ref.close
datadir='/temp/dataset'
path_dir={}
x_train=[]
t_train=[]
image=[]
for img in os.listdir(datadir):
            path=os.path.join(datadir,img)
            num_path=path.split('(')
            num_path=num_path[1].split(')')
            #print(num_path[0])
            if((num_path[0]!=22)and(num_path[0]!=30)and(num_path[0]!=31)and(num_path[0]!=33)):
              path_dir[int(num_path[0])]=path
#len(path_dir.keys())
for i in range (1,50):
  if((i!=22)and(i!=30)and(i!=31)and(i!=33)):
    image.append((cv.imread(path_dir[i],0)))
    img=cv.imread(path_dir[i])
    #cv.imshow('jo',img)
    img=getx(img)
    img=np.array(img)/255
    #cv.imshow(str(i),img)
    if(len(x_train)<40):
        x_train.append(img)
    else:
        t_train.append(img)

zip_ref=zipfile.ZipFile('/content/drive/MyDrive/datafiles.zip','r')
zip_ref.extractall('/temp1')
zip_ref.close

new_datadir='/temp1/datafiles'
new_path_dir={}
y_train=[]
for img in os.listdir(new_datadir):
            path=os.path.join(new_datadir,img)
            num = path.split("(")
            num = num[1].split(")")
            new_path_dir[int(num[0])]=path
mask_points=[]
#print(path_dir[22])
for i in range (1,50):
  if((i!=22)and(i!=30)and(i!=31)and(i!=33)):
    mask_point=[]
    axes=[]
    with open(new_path_dir[i]) as json_file:
                              data = json.load(json_file)
                              for j in range(0,4):
                                axes.append(data[0]["content"][j]['x'])
                                axes.append(data[0]["content"][j]['y'])
                                mask_point.append(axes)
                                axes=[]
                              mask_points.append(mask_point)
                              mask_point=[]
print(len(mask_points))
y_train=[]
for i in range (0,40):
  blank=np.zeros(shape=(256,256),dtype=np.float32)
  points=np.array(mask_points[i],np.int32)
  cv.fillPoly(blank,[points],255)
  blank = blank.tolist()
  y_train.append(np.array(blank))

IMG_WIDTH = 256
IMG_HEIGHT = 256
IMG_CHANNELS = 1


#Build the model
inputs = tf.keras.layers.Input((IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS))
s = tf.keras.layers.Lambda(lambda x: x / 1)(inputs)

#Contraction path
c1 = tf.keras.layers.Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(s)
c1 = tf.keras.layers.Dropout(0.1)(c1)
c1 = tf.keras.layers.Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c1)
p1 = tf.keras.layers.MaxPooling2D((2, 2))(c1)

c2 = tf.keras.layers.Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p1)
c2 = tf.keras.layers.Dropout(0.1)(c2)
c2 = tf.keras.layers.Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c2)
p2 = tf.keras.layers.MaxPooling2D((2, 2))(c2)

c3 = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p2)
c3 = tf.keras.layers.Dropout(0.2)(c3)
c3 = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c3)
p3 = tf.keras.layers.MaxPooling2D((2, 2))(c3)

c4 = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p3)
c4 = tf.keras.layers.Dropout(0.2)(c4)
c4 = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c4)
p4 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))(c4)

c5 = tf.keras.layers.Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(p4)
c5 = tf.keras.layers.Dropout(0.3)(c5)
c5 = tf.keras.layers.Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c5)

#Expansive path
u6 = tf.keras.layers.Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same')(c5)
u6 = tf.keras.layers.concatenate([u6, c4])
c6 = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u6)
c6 = tf.keras.layers.Dropout(0.2)(c6)
c6 = tf.keras.layers.Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c6)

u7 = tf.keras.layers.Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same')(c6)
u7 = tf.keras.layers.concatenate([u7, c3])
c7 = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u7)
c7 = tf.keras.layers.Dropout(0.2)(c7)
c7 = tf.keras.layers.Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c7)

u8 = tf.keras.layers.Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same')(c7)
u8 = tf.keras.layers.concatenate([u8, c2])
c8 = tf.keras.layers.Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u8)
c8 = tf.keras.layers.Dropout(0.1)(c8)
c8 = tf.keras.layers.Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c8)

u9 = tf.keras.layers.Conv2DTranspose(16, (2, 2), strides=(2, 2), padding='same')(c8)
u9 = tf.keras.layers.concatenate([u9, c1])
c9 = tf.keras.layers.Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(u9)
c9 = tf.keras.layers.Dropout(0.1)(c9)
c9 = tf.keras.layers.Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same')(c9)

outputs = tf.keras.layers.Conv2D(1, (1, 1), activation='sigmoid')(c9)

model = tf.keras.Model(inputs=[inputs], outputs=[outputs])
model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])
model.optimizer.learning_rate = 0.001
#model.summary()
x_train=np.array(x_train)
y_train=np.array(y_train)/255

results=model.fit(x_train,y_train,epochs=200)

t_train.append

t_train=np.array(t_train)

model.evaluate(t_train)

import matplotlib.pyplot as plt

plt.imshow(t_train[1])

plt.imshow(model.predict(t_train)[1])





























